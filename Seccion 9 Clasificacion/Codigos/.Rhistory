library(MASS)
Z <- as.data.frame(iris)
Z
X <- Z[,1:4]
X
y <- Z[,5]
y
n <- nrow(X)
n
p <- ncol(X)
p
y
lda.iris <- lda(y ~ .,data=X,CV=TRUE)
lda.iris$class
table.lda <- table(y,lda.iris$class)
table.lda
mis.lda <- n - sum(y==lda.iris$class)
mis.lda/n
col.lda.iris <- c("black","indianred1")[1*(y==lda.iris$class)+1]
pairs(X,main="Good (in red) and bad (in black) classifications for the Iris data set with LDA",pch=19,col=col.lda.iris)
lda.iris$posterior
plot(1:n,lda.iris$posterior[,1],main="Posterior probabilities (blue, group 1, green, group 2 and orange, group 3)",pch=20,col="blue",
xlab="Observation number",ylab="Probabilities")
points(1:n,lda.iris$posterior[,2],pch=20,col="green")
points(1:n,lda.iris$posterior[,3],pch=20,col="orange")
qda.iris <- qda(y ~ .,data=X,CV=TRUE)
qda.iris$class
table.qda <- table(y,qda.iris$class)
table.qda
mis.qda <- n - sum(y==qda.iris$class)
mis.qda/n
col.qda.iris <- c("black","indianred1")[1*(y==qda.iris$class)+1]
pairs(X,main="Good (in red) and bad (in black) classifications for the Iris data set with QDC",pch=19,col=col.qda.iris)
qda.iris$posterior
plot(1:n,qda.iris$posterior[,1],main="Posterior probabilities (blue, group 1, green, group 2 and orange, group 3)",pch=20,col="blue",
xlab="Observation number",ylab="Probabilities")
points(1:n,qda.iris$posterior[,2],pch=20,col="green")
points(1:n,qda.iris$posterior[,3],pch=20,col="orange")
library(MASS)
Z <- as.data.frame(iris)
Z
X <- Z[,1:4]
X
y <- Z[,5]
y
n <- nrow(X)
n
p <- ncol(X)
p
col.iris <- c("blue","green","orange")[y]
col.iris
pairs(X,main="Iris data set",pch=19,col=col.iris)
##################################################################################################################
##################################################################################################################
# ClasificaciÃ³n con kNN
##################################################################################################################
##################################################################################################################
set.seed(1000)
library(class)
knn.class <- vector(mode="list",length=20)
knn.tables <- vector(mode="list",length=20)
knn.mis <- matrix(NA,nrow=20,ncol=1)
for (k in 1 : 20){
knn.class[[k]] <- knn.cv(X,y,k=k)
knn.tables[[k]] <- table(y,knn.class[[k]])
knn.mis[k] <- n - sum(y==knn.class[[k]])
}
knn.mis
which(knn.mis==min(knn.mis))
knn.tables[[14]]
knn.tables[[18]]
knn.tables[[19]]
k.opt <- 14
k.opt
knn.cv.opt <- knn.class[[k.opt]]
knn.cv.opt
knn.tables[[k.opt]]
knn.mis[k.opt]
knn.mis[k.opt]/n
col.knn.iris <- c("black","indianred1")[1*(y==knn.cv.opt)+1]
pairs(X,main="Good (in red) and bad (in black) classifications for the Iris data set with k-NN",pch=19,col=col.knn.iris)
library(MASS)
set.seed(1000)
Z <- as.data.frame(iris)
Z
X <- Z[,1:4]
X
y <- Z[,5]
y
n <- nrow(X)
n
p <- ncol(X)
p
library(nnet)
lr.iris.class <- matrix(0,nrow=n,ncol=1)
lr.iris.probs <- matrix(0,nrow=n,ncol=3)
lr.iris.class
lr.iris.class
lr.iris.probs
for (i in 1:n){
print(i)
lr.iris <- multinom(y[-i] ~ .,data=X[-i,])
lr.iris.probs[i,] <- predict(lr.iris,newdata=X[i,],type="probs")
lr.iris.class[i] <- levels(y)[predict(lr.iris,newdata=X[i,])]
}
lr.iris.class
lr.iris.probs
table.lr <- table(y,lr.iris.class)
table.lr
mis.lr <- n - sum(y==lr.iris.class)
mis.lr/n
col.lr.iris <- c("black","indianred1")[1*(y==lr.iris.class)+1]
pairs(X,main="Good (in red) and bad (in black) classifications for the Iris data set with LR",pch=19,col=col.lr.iris)
lr.iris.probs
plot(1:n,lr.iris.probs[,1],main="Posterior probabilities (blue, group 1, green, group 2 and orange, group 3)",pch=20,col="blue",
xlab="Observation number",ylab="Probabilities")
points(1:n,lr.iris.probs[,2],pch=20,col="green")
points(1:n,lr.iris.probs[,3],pch=20,col="orange")
